{"cells":[{"cell_type":"markdown","metadata":{"id":"PNR351ge7Qb9"},"source":["# Transfer learning & fine-tuning\n","by uramoon@kw.ac.kr<br><br>\n","\n","Xception을 사용하여 고양이와 개를 분류해봅시다.<br>\n","런타임 유형은 가급적 GPU로 설정하세요. (CPU도 가능)<br><br>\n","\n","**Author:** [fchollet](https://twitter.com/fchollet)<br>\n","**Date created:** 2020/04/15<br>\n","**Last modified:** 2020/05/12<br>\n","**Description:** Complete guide to transfer learning & fine-tuning in Keras.<br>\n","(<a href=\"https://raw.githubusercontent.com/ronreiter/interactive-tutorials/master/LICENSE\">Apache 2.0 License</a>)"]},{"cell_type":"markdown","metadata":{"id":"EseCFXYV7QcA"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"yfI7THmn7QcA","executionInfo":{"status":"ok","timestamp":1683724662454,"user_tz":-540,"elapsed":6497,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"markdown","metadata":{"id":"nm0AGWSs7QcB"},"source":["## 소개\n","\n","**전이 학습**은 어떤 문제에 대해 학습된 특징들을 새로운 문제의 풀이에 사용하는 것을 뜻합니다. <br>예를 들면, 라쿤을 인식하는 모델에서 사용되는 특징들로 너구리를 인식하는 데 사용할 수 있을 것입니다.<br>\n","\n","<img src=\"https://extension.umd.edu/sites/extension.umd.edu/files/styles/optimized/public/2021-02/hgic_veg_wildlife_raccoon.jpg?itok=p4k_Z_CF\" height=\"200\"><figcaption>라쿤 사진 출처: https://extension.umd.edu/resource/raccoons</figcaption>\n","\n","<img src=\"https://image-notepet.akamaized.net/resize/620x-/seimage/20171108%2Fe6d1ec360a4ab04e21e580882d9c989e.jpg\" height=\"200\"><figcaption>너구리 사진 출처: https://www.notepet.co.kr/news/article/article_view/?idx=10434</figcaption>\n","\n","\n","# 이 부분 매우 중요, 나중에 꼭 다시 보기 !\n","전이학습은 다음의 수행절차를 갖습니다.\n","1. 기존에 훈련된 모델을 가져온다.\n","2. 가져온 모델을 훈련이 불가능하도록 설정한다. (가중치들을 고정시킴)\n","3. 가져온 모델에 몇 개의 층을 추가한다.\n","* input 에 증강층 추가 \n","* (구글링 : 이미지 데이터 증강을 통한 이미지 분석 모델의 오버피팅 방지, 전 수업시간에 배웠었음)\n","* 데이터의 수가 많지가 않아서 조금씩 변형해서 보여준다. (데이터 수가 부족해서) => 매우 중요 !\n","* output 에 한 개의 unit 추가\n","* imageNet1000 데이터셋이 아니라 이진 분류이기 때문에\n","* output 에 각 Class 에 대한 확률 계산 => \"softmax 함수 이용\"\n","* 그런데 binary classification 일 경우, 한 개의 unit 으로 0과 1 사이를 출력하게 한다. => \"sigmoid 함수 사용\"\n","* 모델에서 가져온 가중치에 대해서는 학습을 시키지 않기 때문에, 내가 추가한 층에 대해서만 훈련을 시킨다. => 빠르게 학습시킬 수 있다.\n","4. 내가 추가한 층만 나의 데이터로 훈련시킨다.\n","\n","추가적으로 고정시킨 모델을 훈련 가능하도록 설정해 세부 튜닝을 시도할 수도 있습니다.\n","\n","This is adapted from\n","[Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)\n"," and the 2016 blog post\n","[\"building powerful image classification models using very little\n"," data\"](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)."]},{"cell_type":"markdown","metadata":{"id":"6MHi_AVw7QcI"},"source":["## 데이터 가져오기\n","원래 25,000장의 그림이 있는데 15,000장만 가져와서 그 중 10,000장은 훈련, 2500장은 검증, 2500장은 테스트에 사용하겠습니다.<br>\n","(오염된 이미지들이 있어서 다 받아오진 못하고 수 백장의 사진이 걸러집니다.)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MvBpIk2u7QcI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683724701417,"user_tz":-540,"elapsed":38967,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"0516aab4-0e99-4522-d134-553b7f3bfeb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:1738 images were corrupted and were skipped\n"]},{"output_type":"stream","name":"stdout","text":["Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\n","Number of training samples: 9305\n","Number of validation samples: 2326\n","Number of test samples: 2326\n"]}],"source":["import tensorflow_datasets as tfds\n","\n","tfds.disable_progress_bar()\n","\n","# 임시 코드 (다운로드가 안되면 지우세요.)\n","setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n","\n","train_ds, validation_ds, test_ds = tfds.load(\n","    \"cats_vs_dogs\",\n","    # Reserve 10% for validation and 10% for test\n","    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n","    as_supervised=True,  # Include labels\n",")\n","\n","print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n","print(\n","    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds)\n",")\n","print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))"]},{"cell_type":"markdown","source":["## TODO1: 데이터셋 전처리하기"],"metadata":{"id":"1X1NIOLN_u6L"}},{"cell_type":"code","source":["# 각 데이터셋의 크기 변경하기\n","size = (150, 150)\n","\n","\n","print(len(train_ds), len(validation_ds), len(test_ds))\n","for ds in [train_ds, validation_ds, test_ds]:\n","    data, = ds.take(1)\n","    print(data[0].shape, data[1]) # image data (index: 0) / label data (index: 1)\n","\n","\n","\n","train_ds = train_ds.map(lambda X, y: (tf.image.resize(X, size), y)) #TODO\n","validation_ds = validation_ds.map(lambda X, y: (tf.image.resize(X, size), y)) #TODO\n","test_ds = test_ds.map(lambda X, y: (tf.image.resize(X, size), y)) #TODO\n","\n","\n","print(\"\\n\\n[ After Resize ]\")\n","for ds in [train_ds, validation_ds, test_ds]:\n","    data, = ds.take(1)\n","    print(data[0].shape, data[1]) # image data (index: 0) / label data (index: 1)"],"metadata":{"id":"kQSbgHOW_0g-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683724702157,"user_tz":-540,"elapsed":747,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"08796a28-414e-4d07-faf3-6e5b4f5aba31"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["9305 2326 2326\n","(262, 350, 3) tf.Tensor(1, shape=(), dtype=int64)\n","(400, 500, 3) tf.Tensor(0, shape=(), dtype=int64)\n","(316, 300, 3) tf.Tensor(0, shape=(), dtype=int64)\n","\n","\n","[ After Resize ]\n","(150, 150, 3) tf.Tensor(1, shape=(), dtype=int64)\n","(150, 150, 3) tf.Tensor(0, shape=(), dtype=int64)\n","(150, 150, 3) tf.Tensor(0, shape=(), dtype=int64)\n"]}]},{"cell_type":"code","source":["# Xception의 전처리 기법 적용하기\n","from tensorflow.keras.applications.xception import Xception\n","from tensorflow.keras.applications.xception import preprocess_input\n","\n","# preprocessing 이전\n","print(\"[ Before Pre-processing ]\")\n","for i, (image, label) in enumerate(train_ds.take(1)):\n","    print(image.shape); print(image[130][130]); print(image[80][36]); print(image[47][90])\n","\n","\n","# 람다 함수를 사용해 각 데이터셋의 X (이미지)에만 preprocess_input을 적용해보세요.\n","# [0, 255] float이 [-1, 1] float으로 바뀝니다.\n","# Hint: 반환할 때 바로 위의 코드 블록과 동일하게 순서쌍의 형태 (이미지, 레이블)로 반환해야 합니다.\n","# 튜플 형태로 반환해야 한다. (data, label)\n","train_ds = train_ds.map(lambda X, y: (preprocess_input(X), y)) #TODO\n","validation_ds = validation_ds.map(lambda X, y: (preprocess_input(X), y)) #TODO\n","test_ds = test_ds.map(lambda X, y: (preprocess_input(X), y)) #TODO\n","\n","# preprocessing 이후\n","print(\"\\n\\n[ After Pre-processing ]\")\n","for i, (image, label) in enumerate(train_ds.take(1)):\n","    print(image.shape); print(image[130][130]); print(image[80][36]); print(image[47][90])\n","\n","type(train_ds.take(1)), type(train_ds)"],"metadata":{"id":"uTwL6NIE_-3l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683724702469,"user_tz":-540,"elapsed":314,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"cc03e81b-8435-418d-86fa-405f18bb97d9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[ Before Pre-processing ]\n","(150, 150, 3)\n","tf.Tensor([60.320007 44.320007 31.320007], shape=(3,), dtype=float32)\n","tf.Tensor([183.5154  181.03983 167.63536], shape=(3,), dtype=float32)\n","tf.Tensor([121.57789  86.68903  69.33353], shape=(3,), dtype=float32)\n","\n","\n","[ After Pre-processing ]\n","(150, 150, 3)\n","tf.Tensor([-0.5269019  -0.6523921  -0.75435287], shape=(3,), dtype=float32)\n","tf.Tensor([0.43933642 0.4199202  0.31478715], shape=(3,), dtype=float32)\n","tf.Tensor([-0.04644793 -0.320086   -0.45620763], shape=(3,), dtype=float32)\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensorflow.python.data.ops.take_op._TakeDataset,\n"," tensorflow.python.data.ops.map_op._MapDataset)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# 데이터셋을 32장씩 묶읍시다.\n","batch_size = 32\n","\n","train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10) #TODO\n","validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10) #TODO\n","test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10) #TODO"],"metadata":{"id":"A5WzWUapAcVd","executionInfo":{"status":"ok","timestamp":1683724702469,"user_tz":-540,"elapsed":5,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hhtbx3Xq7QcK"},"source":["## TODO2: 데이터 증강 층 만들기<br>\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"cFmmTjHU7QcK","executionInfo":{"status":"ok","timestamp":1683724702470,"user_tz":-540,"elapsed":5,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","\n","# 좌우로만 뒤집는 층과 360도의 10%만큼 시계, 반시계로 회전하는 층을 만들어보세요.\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"), #TODO: 각 괄호 안에 적절한 값을 넣으셔야 합니다.\n","        layers.RandomRotation(0.1), #TODO: 이 층 뒤에 계속 다른 층이 연결될 예정이라 Comma를 지우시면 안됩니다. \n","    ] \n",")#TODO"]},{"cell_type":"markdown","metadata":{"id":"0vZcwfo47QcK"},"source":["## TODO3: 모델 정의하기\n","\n","가져온 모델 앞에 입력층과 데이터 증강층을 추가하고 뒤에 예측하는 부분 (MLP와 같은 Dense층) 을 추가합니다."]},{"cell_type":"code","source":["from keras import models\n","from keras import layers\n","from tensorflow.keras import optimizers\n","\n","base_model = keras.applications.Xception(\n","    weights=\"imagenet\", # ImageNet에 대해서 훈련된 모델을 가져옵니다.\n","    input_shape=(150, 150, 3),\n","    include_top=False,  # 개와 고양이를 예측할 것이기 때문에 ImageNet 데이터를 예측하는 출력층은 포함하지 않습니다.\n",")  \n","# Xception은 훈련이 불가능하도록 설정합니다.\n","base_model.trainable = False\n","\n","model = models.Sequential()\n","\n","#TODO: 입력층 추가\n","model.add(layers.Input(shape=(150, 150, 3)))\n","\n","\n","#TODO: 데이터 증강층 추가\n","model.add(data_augmentation) # 매우 중요 !\n","\n","\n","\n","#가져온 모델 추가\n","model.add(base_model)\n","\n","\n","\n","# MLP는 일차원으로 펼쳐진 입력이 필요합니다. \n","# 아래 둘 중 원하는 것 하나만 쓰세요.\n","# Xception은 5 x 5 사이즈의 2048개 채널을 출력합니다.\n","#model.add(layers.Flatten()) # 각 채널의 모든 픽셀들을 일차원으로 이어붙이는 무식하고 낡은 방법 (25개 x 2048장 = (5 x 5) 채널 x 2048장)\n","model.add(layers.GlobalAveragePooling2D()) # 각 5 x 5 채널을 하나의 값으로 요약한 후 일차원으로 이어붙이는 방법 (2048개)\n","\n","\n","\n","# 출력층 추가 (0~1 출력하는 노드 하나만 필요하고 적절한 활성화 함수 기재)\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","\n","# 컴파일\n","model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"])"],"metadata":{"id":"AoJ0jaoUCKpI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683724705550,"user_tz":-540,"elapsed":3085,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"cede60cf-3ca7-435d-af32-b65f736c73a9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83683744/83683744 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# 직접 만들었던 모델과 비교해보세요.\n","model.summary()"],"metadata":{"id":"ysKY9a2VDzPP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683724705550,"user_tz":-540,"elapsed":16,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"4c62ce96-c0c8-4aa1-a80b-a7667dadd6f4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential (Sequential)     (None, 150, 150, 3)       0         \n","                                                                 \n"," xception (Functional)       (None, 5, 5, 2048)        20861480  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 1)                 2049      \n","                                                                 \n","=================================================================\n","Total params: 20,863,529\n","Trainable params: 2,049\n","Non-trainable params: 20,861,480\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"l_9fLIML7QcL"},"source":["## TODO4: 훈련하기"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"OjvNyH3y7QcL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683727283859,"user_tz":-540,"elapsed":2578316,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"2a2e6a0d-ff03-444a-d27c-edd32451d8ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","291/291 [==============================] - 38s 87ms/step - loss: 0.3685 - accuracy: 0.8546 - val_loss: 0.1847 - val_accuracy: 0.9428\n","Epoch 2/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.1302 - val_accuracy: 0.9587\n","Epoch 3/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.1528 - accuracy: 0.9450 - val_loss: 0.1114 - val_accuracy: 0.9604\n","Epoch 4/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.1400 - accuracy: 0.9433 - val_loss: 0.1011 - val_accuracy: 0.9622\n","Epoch 5/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1291 - accuracy: 0.9494 - val_loss: 0.0950 - val_accuracy: 0.9652\n","Epoch 6/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1290 - accuracy: 0.9491 - val_loss: 0.0908 - val_accuracy: 0.9665\n","Epoch 7/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1186 - accuracy: 0.9536 - val_loss: 0.0877 - val_accuracy: 0.9678\n","Epoch 8/10000\n","291/291 [==============================] - 24s 81ms/step - loss: 0.1171 - accuracy: 0.9535 - val_loss: 0.0854 - val_accuracy: 0.9673\n","Epoch 9/10000\n","291/291 [==============================] - 24s 81ms/step - loss: 0.1194 - accuracy: 0.9535 - val_loss: 0.0840 - val_accuracy: 0.9660\n","Epoch 10/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.1120 - accuracy: 0.9555 - val_loss: 0.0824 - val_accuracy: 0.9678\n","Epoch 11/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1142 - accuracy: 0.9530 - val_loss: 0.0814 - val_accuracy: 0.9678\n","Epoch 12/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.1093 - accuracy: 0.9554 - val_loss: 0.0800 - val_accuracy: 0.9686\n","Epoch 13/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1068 - accuracy: 0.9580 - val_loss: 0.0797 - val_accuracy: 0.9686\n","Epoch 14/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.1059 - accuracy: 0.9574 - val_loss: 0.0799 - val_accuracy: 0.9678\n","Epoch 15/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1072 - accuracy: 0.9581 - val_loss: 0.0779 - val_accuracy: 0.9686\n","Epoch 16/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1057 - accuracy: 0.9568 - val_loss: 0.0774 - val_accuracy: 0.9695\n","Epoch 17/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.1052 - accuracy: 0.9563 - val_loss: 0.0768 - val_accuracy: 0.9695\n","Epoch 18/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.1024 - accuracy: 0.9578 - val_loss: 0.0764 - val_accuracy: 0.9690\n","Epoch 19/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.1010 - accuracy: 0.9577 - val_loss: 0.0765 - val_accuracy: 0.9690\n","Epoch 20/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0961 - accuracy: 0.9592 - val_loss: 0.0758 - val_accuracy: 0.9695\n","Epoch 21/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.1014 - accuracy: 0.9588 - val_loss: 0.0756 - val_accuracy: 0.9695\n","Epoch 22/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.1008 - accuracy: 0.9609 - val_loss: 0.0753 - val_accuracy: 0.9682\n","Epoch 23/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0966 - accuracy: 0.9623 - val_loss: 0.0754 - val_accuracy: 0.9686\n","Epoch 24/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.0921 - accuracy: 0.9643 - val_loss: 0.0746 - val_accuracy: 0.9695\n","Epoch 25/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0932 - accuracy: 0.9628 - val_loss: 0.0740 - val_accuracy: 0.9695\n","Epoch 26/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0942 - accuracy: 0.9628 - val_loss: 0.0742 - val_accuracy: 0.9686\n","Epoch 27/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.0944 - accuracy: 0.9631 - val_loss: 0.0741 - val_accuracy: 0.9682\n","Epoch 28/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0939 - accuracy: 0.9626 - val_loss: 0.0739 - val_accuracy: 0.9682\n","Epoch 29/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0965 - accuracy: 0.9596 - val_loss: 0.0736 - val_accuracy: 0.9682\n","Epoch 30/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.0935 - accuracy: 0.9635 - val_loss: 0.0730 - val_accuracy: 0.9690\n","Epoch 31/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.0923 - accuracy: 0.9628 - val_loss: 0.0751 - val_accuracy: 0.9695\n","Epoch 32/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0903 - accuracy: 0.9653 - val_loss: 0.0739 - val_accuracy: 0.9690\n","Epoch 33/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.0933 - accuracy: 0.9635 - val_loss: 0.0720 - val_accuracy: 0.9690\n","Epoch 34/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0889 - accuracy: 0.9642 - val_loss: 0.0724 - val_accuracy: 0.9690\n","Epoch 35/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0902 - accuracy: 0.9646 - val_loss: 0.0722 - val_accuracy: 0.9695\n","Epoch 36/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0926 - accuracy: 0.9652 - val_loss: 0.0722 - val_accuracy: 0.9695\n","Epoch 37/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0887 - accuracy: 0.9655 - val_loss: 0.0733 - val_accuracy: 0.9690\n","Epoch 38/10000\n","291/291 [==============================] - 23s 79ms/step - loss: 0.0933 - accuracy: 0.9631 - val_loss: 0.0714 - val_accuracy: 0.9708\n","Epoch 39/10000\n","291/291 [==============================] - 23s 79ms/step - loss: 0.0899 - accuracy: 0.9645 - val_loss: 0.0719 - val_accuracy: 0.9699\n","Epoch 40/10000\n","291/291 [==============================] - 22s 76ms/step - loss: 0.0876 - accuracy: 0.9677 - val_loss: 0.0717 - val_accuracy: 0.9712\n","Epoch 41/10000\n","291/291 [==============================] - 23s 79ms/step - loss: 0.0878 - accuracy: 0.9657 - val_loss: 0.0711 - val_accuracy: 0.9721\n","Epoch 42/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.0857 - accuracy: 0.9656 - val_loss: 0.0718 - val_accuracy: 0.9699\n","Epoch 43/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.0836 - accuracy: 0.9664 - val_loss: 0.0724 - val_accuracy: 0.9695\n","Epoch 44/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0842 - accuracy: 0.9682 - val_loss: 0.0720 - val_accuracy: 0.9686\n","Epoch 45/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0818 - accuracy: 0.9673 - val_loss: 0.0712 - val_accuracy: 0.9712\n","Epoch 46/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0870 - accuracy: 0.9663 - val_loss: 0.0710 - val_accuracy: 0.9712\n","Epoch 47/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0837 - accuracy: 0.9680 - val_loss: 0.0718 - val_accuracy: 0.9690\n","Epoch 48/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0852 - accuracy: 0.9659 - val_loss: 0.0714 - val_accuracy: 0.9703\n","Epoch 49/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0847 - accuracy: 0.9655 - val_loss: 0.0717 - val_accuracy: 0.9695\n","Epoch 50/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0848 - accuracy: 0.9656 - val_loss: 0.0712 - val_accuracy: 0.9708\n","Epoch 51/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0835 - accuracy: 0.9672 - val_loss: 0.0725 - val_accuracy: 0.9690\n","Epoch 52/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0819 - accuracy: 0.9690 - val_loss: 0.0719 - val_accuracy: 0.9699\n","Epoch 53/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0797 - accuracy: 0.9688 - val_loss: 0.0707 - val_accuracy: 0.9708\n","Epoch 54/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0843 - accuracy: 0.9687 - val_loss: 0.0711 - val_accuracy: 0.9703\n","Epoch 55/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0860 - accuracy: 0.9668 - val_loss: 0.0709 - val_accuracy: 0.9703\n","Epoch 56/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0834 - accuracy: 0.9658 - val_loss: 0.0707 - val_accuracy: 0.9703\n","Epoch 57/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0817 - accuracy: 0.9673 - val_loss: 0.0707 - val_accuracy: 0.9703\n","Epoch 58/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0828 - accuracy: 0.9680 - val_loss: 0.0712 - val_accuracy: 0.9703\n","Epoch 59/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0815 - accuracy: 0.9660 - val_loss: 0.0703 - val_accuracy: 0.9708\n","Epoch 60/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0808 - accuracy: 0.9703 - val_loss: 0.0707 - val_accuracy: 0.9695\n","Epoch 61/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0818 - accuracy: 0.9661 - val_loss: 0.0708 - val_accuracy: 0.9699\n","Epoch 62/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0813 - accuracy: 0.9694 - val_loss: 0.0705 - val_accuracy: 0.9695\n","Epoch 63/10000\n","291/291 [==============================] - 24s 81ms/step - loss: 0.0791 - accuracy: 0.9696 - val_loss: 0.0711 - val_accuracy: 0.9690\n","Epoch 64/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.0853 - accuracy: 0.9650 - val_loss: 0.0708 - val_accuracy: 0.9695\n","Epoch 65/10000\n","291/291 [==============================] - 23s 77ms/step - loss: 0.0812 - accuracy: 0.9686 - val_loss: 0.0711 - val_accuracy: 0.9690\n","Epoch 66/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0786 - accuracy: 0.9694 - val_loss: 0.0701 - val_accuracy: 0.9712\n","Epoch 67/10000\n","291/291 [==============================] - 22s 76ms/step - loss: 0.0809 - accuracy: 0.9675 - val_loss: 0.0714 - val_accuracy: 0.9690\n","Epoch 68/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0785 - accuracy: 0.9684 - val_loss: 0.0708 - val_accuracy: 0.9695\n","Epoch 69/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0810 - accuracy: 0.9682 - val_loss: 0.0706 - val_accuracy: 0.9695\n","Epoch 70/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0813 - accuracy: 0.9680 - val_loss: 0.0696 - val_accuracy: 0.9712\n","Epoch 71/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.0830 - accuracy: 0.9672 - val_loss: 0.0706 - val_accuracy: 0.9690\n","Epoch 72/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0809 - accuracy: 0.9679 - val_loss: 0.0699 - val_accuracy: 0.9699\n","Epoch 73/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0771 - accuracy: 0.9701 - val_loss: 0.0700 - val_accuracy: 0.9699\n","Epoch 74/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0765 - accuracy: 0.9703 - val_loss: 0.0706 - val_accuracy: 0.9686\n","Epoch 75/10000\n","291/291 [==============================] - 23s 80ms/step - loss: 0.0827 - accuracy: 0.9677 - val_loss: 0.0701 - val_accuracy: 0.9690\n","Epoch 76/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0758 - accuracy: 0.9703 - val_loss: 0.0706 - val_accuracy: 0.9686\n","Epoch 77/10000\n","291/291 [==============================] - 22s 77ms/step - loss: 0.0789 - accuracy: 0.9700 - val_loss: 0.0712 - val_accuracy: 0.9686\n","Epoch 78/10000\n","291/291 [==============================] - 23s 78ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.0702 - val_accuracy: 0.9699\n","Epoch 79/10000\n","291/291 [==============================] - 22s 76ms/step - loss: 0.0781 - accuracy: 0.9697 - val_loss: 0.0706 - val_accuracy: 0.9699\n","Epoch 80/10000\n","291/291 [==============================] - 22s 76ms/step - loss: 0.0761 - accuracy: 0.9710 - val_loss: 0.0705 - val_accuracy: 0.9703\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd25eea3e80>"]},"metadata":{},"execution_count":9}],"source":["from keras.callbacks import EarlyStopping\n","\n","# TODO: 자유롭게 설정하세요.\n","epochs = 10000\n","es = EarlyStopping(patience=10, restore_best_weights=True) #TODO\n","model.fit(train_ds, epochs=epochs, callbacks=es, validation_data=validation_ds)"]},{"cell_type":"markdown","source":["## 테스트 데이터로 평가해보기"],"metadata":{"id":"Arcvlsa_Ge7p"}},{"cell_type":"code","source":["model.evaluate(test_ds)"],"metadata":{"id":"xwHixM5yGhIJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683727288742,"user_tz":-540,"elapsed":4889,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"4fd1b1d8-ef05-4530-a288-d3b0bdd18714"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["73/73 [==============================] - 5s 61ms/step - loss: 0.0711 - accuracy: 0.9768\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.07108655571937561, 0.9767841696739197]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FW0TLL%2FbtqRx0uGeC2%2FKxbOgpwhzXXvwu1VtcmjNK%2Fimg.jpg' height=200>"],"metadata":{"id":"e7MyLKdpGhug"}},{"cell_type":"markdown","metadata":{"id":"qA2QpMBl7QcL"},"source":["## 세부 튜닝하기 (fine-tuning)\n","\n","가져온 모델인 Xception까지 우리 데이터에 맞게 훈련해봅시다.<br>\n","너무 많은 시간이 소요될 수 있으니 적당히 수행합니다. (중간에 중단 버튼 눌러도 괜찮음)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"WSBAgWEj7QcL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683728257157,"user_tz":-540,"elapsed":968426,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"f5ae7814-953b-4d5a-fe8e-49b6f8dabefe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential (Sequential)     (None, 150, 150, 3)       0         \n","                                                                 \n"," xception (Functional)       (None, 5, 5, 2048)        20861480  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 1)                 2049      \n","                                                                 \n","=================================================================\n","Total params: 20,863,529\n","Trainable params: 20,809,001\n","Non-trainable params: 54,528\n","_________________________________________________________________\n","Epoch 1/10000\n","291/291 [==============================] - 120s 246ms/step - loss: 0.1482 - accuracy: 0.9418 - val_loss: 0.0675 - val_accuracy: 0.9703\n","Epoch 2/10000\n","291/291 [==============================] - 68s 233ms/step - loss: 0.0582 - accuracy: 0.9775 - val_loss: 0.0531 - val_accuracy: 0.9789\n","Epoch 3/10000\n","291/291 [==============================] - 68s 232ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.0558 - val_accuracy: 0.9798\n","Epoch 4/10000\n","291/291 [==============================] - 67s 231ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0702 - val_accuracy: 0.9794\n","Epoch 5/10000\n","291/291 [==============================] - 67s 231ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0679 - val_accuracy: 0.9789\n","Epoch 6/10000\n","291/291 [==============================] - 68s 233ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0704 - val_accuracy: 0.9819\n","Epoch 7/10000\n","291/291 [==============================] - 67s 231ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0847 - val_accuracy: 0.9742\n","Epoch 8/10000\n","291/291 [==============================] - 68s 232ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0859 - val_accuracy: 0.9746\n","Epoch 9/10000\n","291/291 [==============================] - 68s 234ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.0918 - val_accuracy: 0.9751\n","Epoch 10/10000\n","291/291 [==============================] - 67s 231ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0618 - val_accuracy: 0.9785\n","Epoch 11/10000\n","291/291 [==============================] - 68s 233ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0543 - val_accuracy: 0.9802\n","Epoch 12/10000\n","291/291 [==============================] - 67s 231ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0951 - val_accuracy: 0.9742\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd25e6fb070>"]},"metadata":{},"execution_count":11}],"source":["# 가져온 모델 훈련 가능하도록 설정\n","base_model.trainable = True\n","\n","# 훈련 가능한 파라미터 수를 위와 비교해보세요.\n","model.summary()\n","\n","# 컴파일 해주세요.\n","model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"]) #TODO\n","\n","# 방금 훈련한 모델을 조금 더 훈련시킵니다.\n","epochs = 10000 #TODO\n","model.fit(train_ds, epochs=epochs, callbacks=es, validation_data=validation_ds)"]},{"cell_type":"markdown","metadata":{"id":"1x3KXtZY7QcL"},"source":["## 다시 테스트 데이터로 평가해보기"]},{"cell_type":"code","source":["model.evaluate(test_ds)"],"metadata":{"id":"Phq2K78YL9E6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683728261214,"user_tz":-540,"elapsed":4068,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"23d394eb-6112-4f14-ff08-6a0a5280cdbd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["73/73 [==============================] - 4s 61ms/step - loss: 0.0719 - accuracy: 0.9755\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.07186746597290039, 0.975494384765625]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["적은 시간을 사용했을 경우 오히려 성능이 떨어질 가능성이 높습니다.<br>\n","원본 노트북에서는 훈련 불가능하게 만든 상태에서 20 epochs, 세부 튜닝에서 10 epochs 훈련하는데 성능이 조금 좋아집니다.<br>\n","전이학습에서 세부 튜닝하는 방법까지 공부한 것에 의의를 둡시다."],"metadata":{"id":"TYMX7_kXMETZ"}}],"metadata":{"colab":{"provenance":[{"file_id":"1Z74-11S6od-4CdTc-teJV5CEcaTL2WxI","timestamp":1683516702371},{"file_id":"1C93wfhxSGZ2Eux2GPGTLlzn1uhcPrw5Q","timestamp":1653141367451},{"file_id":"1u9fRCvTPZJc-g2Lu_3oMozqkOQZwyEwa","timestamp":1649250419614},{"file_id":"https://github.com/keras-team/keras-io/blob/master/guides/ipynb/transfer_learning.ipynb","timestamp":1649249435073}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}