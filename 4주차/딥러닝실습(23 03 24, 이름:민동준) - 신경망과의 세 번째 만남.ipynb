{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"provenance":[{"file_id":"14EbZY7wE73yoyqEF3Q4V4V0hcJ2xSJdo","timestamp":1679640617429},{"file_id":"1M86QKUYfVMpRL0IxvBdwfE3LAGt7jl3v","timestamp":1679208900892},{"file_id":"1oook0YohWE0ixXTC7QXBBekJGlPIjtWQ","timestamp":1651650497064},{"file_id":"1ASblNicAc3-HrzR7FWHvJ3NxE3OkEF79","timestamp":1646227867852},{"file_id":"https://github.com/rickiepark/deep-learning-with-python-notebooks/blob/master/2.1-a-first-look-at-a-neural-network.ipynb","timestamp":1611894898932}]},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"cL0Fa8CzavHX"},"source":["# 신경망과의 세 번째 만남\n","by uramoon@kw.ac.kr (<a href=\"https://raw.githubusercontent.com/ronreiter/interactive-tutorials/master/LICENSE\">Apache 2.0 License</a>)\n","\n","2004년 MS 연구소에서 발표한 논문에 포함된 MLP (Multi-Layer Perceptron, 유닛 800개 들어간 은닉층 하나만 사용)의 MNIST 테스트 정확도는 98.4%입니다. 같은 논문에서 훈련 데이터를 늘리고 이미지를 이차원 형태로 해석하는 능력을 갖춘 합성곱 신경망 (CNN, Convolution neural network)을 사용했을 때 99.6%를 달성했습니다.\n","\n","\n","\n","본 노트북에서는 MLP의 epochs를 자동으로 설정하여 테스트 정확도를 98.3% 이상으로 만드는 것을 목표로 합니다."]},{"cell_type":"code","metadata":{"id":"hl8n95y_avHS","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1679667220132,"user_tz":-540,"elapsed":2953,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"9028e58f-de40-42b2-af4f-042883c5334e"},"source":["import keras\n","keras.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.11.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["## 데이터셋 불러오기 & 이미지 전처리\n"],"metadata":{"id":"orxCsBOIr2w8"}},{"cell_type":"code","metadata":{"id":"CCBjPiT9avHY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679667221729,"user_tz":-540,"elapsed":1607,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"a5b669e4-4eae-4755-fa41-43d3b494de05"},"source":["# TODO: MNIST 데이터셋 불러오기\n","\n","# MNIST 데이터셋 불러오기\n","from keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","print(\"[ before preprocessing ]\")\n","print(train_images.shape, test_images.shape)\n","print(train_labels.shape, test_labels.shape)\n","\n","# TODO: 이미지 전처리\n","# [0, 255]의 3차원 배열을 [0, 1]의 2차원 배열로 변환\n","\n","norm_train_images = train_images.reshape((60000, 784))      # 6만개의 일차원 배열로 재해석 (각 배열은 길이 784=28*28)\n","norm_train_images = norm_train_images.astype('float32') / 255   # [0, 255]의 정수를 [0, 1]의 실수로 변환\n","train_images = norm_train_images\n","\n","norm_test_images = test_images.reshape((10000, 784))\n","norm_test_images = norm_test_images.astype('float32') / 255\n","test_images = norm_test_images\n","\n","print(\"\\n[ after preprocessing ]\")\n","print(train_images.shape, test_images.shape)\n","print(train_labels.shape, test_labels.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","[ before preprocessing ]\n","(60000, 28, 28) (10000, 28, 28)\n","(60000,) (10000,)\n","\n","[ after preprocessing ]\n","(60000, 784) (10000, 784)\n","(60000,) (10000,)\n"]}]},{"cell_type":"markdown","source":["## 분류 문제의 출력층과 손실 (loss) 함수\n","\n","출력 유닛의 수가 **2 이상**인 분류 문제에서 출력층의 활성화 함수로는 지난 시간에 사용한 **softmax**를 사용합니다. 출력층의 각 유닛은 일반적으로 $(-\\infty,+\\infty)$의 값을 출력하는데 softmax는 그들 중 가장 큰 값에 가장 높은 확률을 부여합니다. (동시에 모든 확률을 더했을 때 1이 되도록 만듦)\n","\n","\n","손실 (loss) 함수는 출력층의 출력 내용이 이상적인 출력 내용과 얼마나 동떨어졌는지 계산합니다. (loss가 클수록 나쁨) \n","\n","출력 유닛의 수가 **2 이상**인 분류 문제에서 사용할 수 있는 대표적인 손실 함수는 다음의 두 개가 있습니다:\n","\n","1. categorical_crossentropy: 지난 시간에 사용한 함수로 정답 (label)이 5인 경우  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]와 같이 **label을 변환**해야 한다.\n","2. sparse_categorical_crossentropy: 정답 (label)이 5인 경우 5를 [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]로 해석하여 loss를 계산하므로 **label을 변환할 필요가 없다.** (5를 봤을 때 5번째 인덱스의 출력은 1이고, 나머지는 0으로 해석)\n","\n","이 번 노트북에서는 **label을 변환하지 않고, sparse_categorical_crossentropy를 사용해봅시다.**\n","\n","--- \n","\n","출력 유닛의 수가 1인 이진 분류 (binary classification)의 출력층에서는 **softmax를 사용하면 안됩니다.** softmax는 여러 개의 출력을 확률로 변환하는데, 출력이 하나 밖에 없으므로 하나의 출력을 무조건 1로 만들어주기 때문입니다. 이진 분류 문제에서는 출력층에서 sigmoid 함수를 사용하여 $(-\\infty,+\\infty)$의 값을 (0, 1)의 값으로 바꿔줍니다. (예: 고양이와 개를 분류할 때 고양이일 확률이 $p$라면, 개일 확률은 $1-p$로 해석합니다.)\n","\n"],"metadata":{"id":"fHwfu4QlI3gT"}},{"cell_type":"markdown","source":["## MLP 만들기\n","\n","문제에 따라서 효율적인 인공신경망 구조가 있으나 직접 해보기 전까지는 어떠한 구조가 잘 동작할 지 알 수 없습니다.<br> 편의상 신경망과의 첫 만남 때 사용한 것과 동일한 네트워크를 사용합니다."],"metadata":{"id":"NrzI8foUsoU7"}},{"cell_type":"code","metadata":{"id":"YAuPjlTTavHb","executionInfo":{"status":"ok","timestamp":1679667225009,"user_tz":-540,"elapsed":3285,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"source":["# TODO: 네트워크 만들기, loss만 써주세요.\n","from keras import models\n","from keras import layers\n","\n","network = models.Sequential()\n","network.add(layers.Input(784,)) # (784)는 784라는 정수, (784,)는 길이 784인 일차원 배열을 의미\n","network.add(layers.Dense(512, activation='relu')) \n","network.add(layers.Dense(10, activation='softmax')) \n","\n","network.compile(optimizer='rmsprop',              \n","                # loss='categorical_crossentropy',  \n","                loss='sparse_categorical_crossentropy',  \n","                metrics=['accuracy'])          "],"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## EarlyStopping 사용하기\n","\n","epochs를 무작정 키울 수 없는 것은 인공신경망이 훈련 데이터에 과적합되어 보지 못한 테스트 데이터에서의 성능이 떨어질까 걱정되기 때문입니다. 이를 방지하려면 훈련 데이터의 일부를 훈련 중 볼 수 없는 **검증 데이터**로 활용하면 됩니다.\n","\n","**검증 데이터**를 사용하면 테스트 데이터를 사용하지 않고도 훈련 중에 **테스트 데이터에서의 성능을 미리 가늠**해볼 수 있습니다. 훈련 중 epoch이 끝날 때마다 검증 데이터에서의 성능을 평가하여 과적합 조짐 (훈련 데이터에서의 성능은 올라갔으나 훈련 중 보지 못한 검증 데이터에서의 성능은 하락)이 보이면 훈련을 그만두도록 설정할 수 있습니다."],"metadata":{"id":"iS6BKDqi2Ic2"}},{"cell_type":"code","source":["# TODO: EarlyStopping을 사용하여 훈련하기\n","# Test Accuracy 98.3% 이상을 달성하세요.\n","# 처음부터 훈련하려면 위의 코드블록도 다시 실행하고, 기존의 신경망으로 이어서 훈련하려면 이 코드 블록만 다시 실행합니다.\n","from keras.callbacks import EarlyStopping\n","\n","network.fit(train_images, train_labels, batch_size=128, epochs=10000, # 수정불가: 만 번의 epochs 전에 조기종료를 할 것입니다.\n","            callbacks=EarlyStopping(patience=30),                  # 검증 데이터에서의 val_loss 성능 하락을 최대 몇 번 참을지 적절하게 설정\n","            validation_split=0.1)                                     # 훈련 데이터에서 검증 데이터로 얼마나 사용할지 적절하게 설정\n","\n","test_loss, test_acc = network.evaluate(test_images, test_labels)\n","print(f'Test Accuracy:{test_acc * 100:.2f}%')"],"metadata":{"id":"ndWLQDN8tgcL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679667309994,"user_tz":-540,"elapsed":84988,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"84c71a49-bdd6-4c55-8add-2a49969bc1ca"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000\n","422/422 [==============================] - 10s 4ms/step - loss: 0.2819 - accuracy: 0.9187 - val_loss: 0.1319 - val_accuracy: 0.9628\n","Epoch 2/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.1155 - accuracy: 0.9663 - val_loss: 0.0887 - val_accuracy: 0.9750\n","Epoch 3/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0758 - accuracy: 0.9777 - val_loss: 0.0758 - val_accuracy: 0.9777\n","Epoch 4/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9841 - val_loss: 0.0657 - val_accuracy: 0.9800\n","Epoch 5/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.0626 - val_accuracy: 0.9827\n","Epoch 6/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.0617 - val_accuracy: 0.9818\n","Epoch 7/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.0594 - val_accuracy: 0.9833\n","Epoch 8/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0663 - val_accuracy: 0.9822\n","Epoch 9/10000\n","422/422 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0664 - val_accuracy: 0.9837\n","Epoch 10/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0621 - val_accuracy: 0.9840\n","Epoch 11/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0652 - val_accuracy: 0.9843\n","Epoch 12/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0689 - val_accuracy: 0.9825\n","Epoch 13/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0678 - val_accuracy: 0.9853\n","Epoch 14/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0653 - val_accuracy: 0.9852\n","Epoch 15/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0680 - val_accuracy: 0.9853\n","Epoch 16/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 9.9353e-04 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9843\n","Epoch 17/10000\n","422/422 [==============================] - 2s 4ms/step - loss: 7.2674e-04 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9850\n","Epoch 18/10000\n","422/422 [==============================] - 2s 4ms/step - loss: 5.9034e-04 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9857\n","Epoch 19/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 4.4900e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9860\n","Epoch 20/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 3.8833e-04 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9853\n","Epoch 21/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 3.2889e-04 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9862\n","Epoch 22/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 2.8987e-04 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9863\n","Epoch 23/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 2.6698e-04 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9863\n","Epoch 24/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 2.4039e-04 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9860\n","Epoch 25/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 2.2008e-04 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9858\n","Epoch 26/10000\n","422/422 [==============================] - 1s 4ms/step - loss: 2.0869e-04 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9855\n","Epoch 27/10000\n","422/422 [==============================] - 2s 4ms/step - loss: 1.9211e-04 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9858\n","Epoch 28/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.8006e-04 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9858\n","Epoch 29/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.7090e-04 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9857\n","Epoch 30/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.6115e-04 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9852\n","Epoch 31/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.5298e-04 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9853\n","Epoch 32/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.4519e-04 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9853\n","Epoch 33/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.3881e-04 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9855\n","Epoch 34/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.3226e-04 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9858\n","Epoch 35/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.2743e-04 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9857\n","Epoch 36/10000\n","422/422 [==============================] - 2s 4ms/step - loss: 1.2220e-04 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9862\n","Epoch 37/10000\n","422/422 [==============================] - 1s 3ms/step - loss: 1.1739e-04 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9855\n","313/313 [==============================] - 1s 2ms/step - loss: 0.0736 - accuracy: 0.9832\n","Test Accuracy:98.32%\n"]}]},{"cell_type":"markdown","source":["epoch이 진행되며 훈련 데이터에서의 성능은 비교적 꾸준히 좋아지지만 (loss는 낮아지고, accuracy는 높아짐) 검증 데이터로 측정한 val_loss와 val_accuracy는 그렇지 않음을 확인해보세요.\n","\n","---\n","\n","MNIST에서 MLP 사용 시 규제가 크게 효과적이지 않아 검증 데이터 없이 모든 훈련 데이터에 과적합시키면 테스트 성능이 좋게 나오는 경향이 있습니다. \n","\n","일반적으로는 전체 데이터에서 훈련:검증:테스트의 비율을 6:2:2로 설정하거나 MNIST에서와 같이 훈련 데이터와 테스트 데이터가 따로 제공되는 경우에는 훈련 데이터의 20% 정도를 검증 데이터로 사용합니다. (MNIST에서는 20%로 설정하면 좋지 않음)\n","\n","앞으로는 얼마나 많은 epochs을 훈련해야 하는지 감이 없을 때 검증 데이터와 EarlyStopping을 활용해 봅시다. (다만 훈련 데이터가 충분하지 않은 경우에는 모두 훈련 데이터로 사용합니다.)"],"metadata":{"id":"aZgtRErcxhnX"}},{"cell_type":"markdown","source":["## 모델 저장하기\n","\n","1. save 함수 이용 (예: network.save('my_mnist.h5')), 보통 확장자는 h5 사용\n","2. 왼쪽 메뉴에서 폴더 모양의 아이콘 (파일) 클릭\n","3. 방금 저장한 파일을 로컬로 다운로드 하기 (점 세개 클릭하면 다운로드 가능, 파일이 안보이면 새로고침 클릭)\n","4. 다운로드 받은 파일 용량 확인해보기\n","\n","다운로드한 모델도 제출합니다."],"metadata":{"id":"r0I7po9WiJtz"}},{"cell_type":"code","source":["network.save('my_mnist.h5')"],"metadata":{"id":"Op_nxUiRiJX6","executionInfo":{"status":"ok","timestamp":1679667309995,"user_tz":-540,"elapsed":26,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a4wz1Ro5ePO8","executionInfo":{"status":"ok","timestamp":1679667309995,"user_tz":-540,"elapsed":24,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"execution_count":5,"outputs":[]}]}