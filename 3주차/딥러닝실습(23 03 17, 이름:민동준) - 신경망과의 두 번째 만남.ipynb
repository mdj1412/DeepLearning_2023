{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"provenance":[{"file_id":"1M86QKUYfVMpRL0IxvBdwfE3LAGt7jl3v","timestamp":1679032785048},{"file_id":"1oook0YohWE0ixXTC7QXBBekJGlPIjtWQ","timestamp":1651650497064},{"file_id":"1ASblNicAc3-HrzR7FWHvJ3NxE3OkEF79","timestamp":1646227867852},{"file_id":"https://github.com/rickiepark/deep-learning-with-python-notebooks/blob/master/2.1-a-first-look-at-a-neural-network.ipynb","timestamp":1611894898932}]},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"AnmcPOWxbQgu"},"source":["by uramoon@kw.ac.kr <br>\n","원본 출처: https://github.com/rickiepark/deep-learning-with-python-notebooks <a href=\"https://github.com/rickiepark/deep-learning-with-python-notebooks/blob/master/LICENSE\">(MIT License)</a>"]},{"cell_type":"code","metadata":{"id":"hl8n95y_avHS","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1679038467255,"user_tz":-540,"elapsed":4016,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"d640357e-ef4d-48b2-c179-25e7517eba96"},"source":["import keras\n","keras.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.11.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"cL0Fa8CzavHX"},"source":["# 신경망과의 두 번째 만남\n","\n","이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 2장 1절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n","\n","----\n","\n","케라스 파이썬 라이브러리를 사용하여 손글씨 숫자 분류를 학습하는 구체적인 신경망 예제를 살펴보겠습니다. 케라스나 비슷한 라이브러리를 사용한 경험이 없다면 당장은 이 첫 번째 예제를 모두 이해하지 못할 것입니다. 아직 케라스를 설치하지 않았을지도 모릅니다. 괜찮습니다. 다음 장에서 이 예제를 하나하나 자세히 설명합니다. 코드가 좀 이상하거나 요술처럼 보이더라도 너무 걱정하지 마세요. 일단 시작해 보겠습니다.\n","\n","여기에서 풀려고 하는 문제는 흑백 손글씨 숫자 이미지(28x28 픽셀)를 10개의 범주(0에서 9까지)로 분류하는 것입니다. 머신 러닝 커뮤니티에서 고전으로 취급받는 데이터셋인 MNIST를 사용하겠습니다. 이 데이터셋은 머신 러닝의 역사만큼 오래되었고 많은 연구에 사용되었습니다. 이 데이터셋은 1980년대에 미국 국립표준기술연구소에서 수집한 6만 개의 훈련 이미지와 1만 개의 테스트 이미지로 구성되어 있습니다. MNIST 문제를 알고리즘이 제대로 작동하는지 확인하기 위한 딥러닝계의 ‘Hello World’라고 생각해도 됩니다. 머신 러닝 기술자가 되기까지 연구 논문이나 블로그 포스트 등에서 MNIST를 보고 또 보게 될 것입니다."]},{"cell_type":"markdown","metadata":{"id":"BPnVPmltavHY"},"source":["MNIST 데이터셋은 넘파이 배열 형태로 케라스에 이미 포함되어 있습니다:"]},{"cell_type":"code","metadata":{"id":"CCBjPiT9avHY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038467764,"user_tz":-540,"elapsed":521,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"0f713d3c-ee6c-4097-b1e7-f3892f2ddb13"},"source":["# TODO: Keras에서 제공하는 MNIST 데이터셋 불러오기\n","from keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"kNoeRx8zavHY"},"source":["`train_images`와 `train_labels`가 모델이 학습해야 할 훈련 세트를 구성합니다. 모델은 `test_images`와 `test_labels`로 구성된 테스트 세트에서 테스트될 것입니다. 이미지는 넘파이 배열로 인코딩되어 있고 레이블은 0에서부터 9까지의 숫자 배열입니다. 이미지와 레이블은 일대일 관계를 가집니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PMCi7plIavHb"},"source":["작업 순서는 다음과 같습니다. 먼저 훈련 데이터 `train_images`와 `train_labels`를 네트워크에 주입합니다. 그러면 네트워크는 이미지와 레이블을 연관시킬 수 있도록 학습됩니다. 마지막으로 `test_images`에 대한 예측을 네트워크에게 요청합니다. 그리고 이 예측이 `test_labels`와 맞는지 확인할 것입니다.\n","\n","신경망을 만들어 보겠습니다. "]},{"cell_type":"code","metadata":{"id":"YAuPjlTTavHb","executionInfo":{"status":"ok","timestamp":1679038472605,"user_tz":-540,"elapsed":4845,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"source":["from keras import models\n","from keras import layers\n","\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,))) # 입력층을 생략하고 이와 같이 간단하게 기재하는 것도 가능\n","network.add(layers.Dense(10, activation='softmax'))"],"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 네트워크의 구조 보기\n","network.summary()"],"metadata":{"id":"QIq6AO6EljdR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038473277,"user_tz":-540,"elapsed":680,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"29d160d4-4b65-42e8-a861-7f5a3050e1b7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 512)               401920    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 407,050\n","Trainable params: 407,050\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"YseI23eKavHb"},"source":["신경망의 핵심 구성 요소는 일종의 데이터 처리 필터라고 생각할 수 있는 층입니다. 어떤 데이터가 들어가면 더 유용한 형태로 출력됩니다. 조금 더 구체적으로 층은 주어진 문제에 더 의미 있는 표현을 입력된 데이터로부터 추출합니다. 대부분의 딥러닝은 간단한 층을 연결하여 구성되어 있고, 점진적으로 데이터를 정제하는 형태를 띠고 있습니다. 딥러닝 모델은 데이터 정제 필터(층)가 연속되어 있는 데이터 프로세싱을 위한 여과기와 같습니다.\n","\n","이 예에서는 조밀하게 연결된 (또는 완전 연결된) 신경망 층인 `Dense` 층 2개가 연속되어 있습니다. 두 번째 (즉, 마지막) 층은 10개의 확률 점수가 들어 있는 배열(모두 더하면 1입니다)을 반환하는 소프트맥스 층입니다. 각 점수는 현재 숫자 이미지가 10개의 숫자 클래스 중 하나에 속할 확률입니다.\n","\n","신경망이 훈련 준비를 마치기 위해서 컴파일 단계에 포함될 세 가지가 더 필요합니다:\n","\n","* 손실 함수 : 훈련 데이터에서 신경망의 성능을 측정하는 방법으로 네트워크가 옳은 방향으로 학습될 수 있도록 도와 줍니다.\n","* 옵티마이저: 입력된 데이터와 손실 함수를 기반으로 네트워크를 업데이트하는 메커니즘입니다.\n","* 훈련과 테스트 과정을 모니터링할 지표 : 여기에서는 정확도(정확히 분류된 이미지의 비율)만 고려하겠습니다.\n","\n","손실 함수와 옵티마이저의 정확한 목적은 이어지는 두 개의 장에서 자세히 설명하겠습니다."]},{"cell_type":"code","metadata":{"id":"zvB6JTrxavHb","executionInfo":{"status":"ok","timestamp":1679038473277,"user_tz":-540,"elapsed":5,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"source":["network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ikDaEzT2avHc"},"source":["훈련을 시작하기 전에 데이터를 네트워크에 맞는 크기로 바꾸고 모든 값을 0과 1 사이로 스케일을 조정합니다. 예를 들어, 앞서 우리의 훈련 이미지는 `[0, 255]` 사이의 값인 `uint8` 타입의 `(60000, 28, 28)` 크기를 가진 배열로 저장되어 있습니다. 이 데이터를 0과 1 사이의 값을 가지는 `float32` 타입의 `(60000, 28 * 28)` 크기의 배열로 바꿉니다."]},{"cell_type":"code","metadata":{"id":"ll4eb4WcavHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038473277,"user_tz":-540,"elapsed":4,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"454dd63f-6bc5-4e8f-d8f0-d8ad59b0baf2"},"source":["# TODO: [0, 255]의 이차원 정수 배열로 표현된 이미지를 \n","# [0, 1]의 일차원 실수 배열로 변환하세요. (Normalization, Scaling, 정규화)\n","\n","norm_train_images = train_images.reshape((60000, 28 * 28))      # 6만개의 일차원 배열로 재해석 (각 배열은 길이 784=28*28)\n","norm_train_images = norm_train_images.astype('float32') / 255   # [0, 255]의 정수를 [0, 1]의 실수로 변환\n","\n","norm_test_images = test_images.reshape((10000, 28 * 28))\n","norm_test_images = norm_test_images.astype('float32') / 255\n","\n","# print(test_images[5], norm_test_images[5])\n","print(test_images.shape, norm_test_images.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 28, 28) (10000, 784)\n"]}]},{"cell_type":"markdown","metadata":{"id":"6kMzm3rYavHc"},"source":["또한, 레이블을 범주형으로 인코딩해야 합니다. 이 단계는 3장에서 자세히 설명하겠습니다:"]},{"cell_type":"code","metadata":{"id":"dpXEeZ-lavHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038473608,"user_tz":-540,"elapsed":333,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"860a124a-9a3e-4d66-dc6d-c467881b10db"},"source":["# TODO: 레이블을 범주형으로 변환 \n","\n","from tensorflow.keras.utils import to_categorical\n","\n","cat_train_labels = to_categorical(train_labels)\n","cat_test_labels = to_categorical(test_labels)\n","\n","train_labels, cat_train_labels"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([5, 0, 4, ..., 5, 6, 8], dtype=uint8),\n"," array([[0., 0., 0., ..., 0., 0., 0.],\n","        [1., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"DMqek4L6avHc"},"source":["이제 신경망을 훈련시킬 준비가 되었습니다. 케라스에서는 `fit` 메서드를 호출하여 훈련 데이터에 모델을 학습시킵니다:"]},{"cell_type":"code","metadata":{"id":"4RYOQNutavHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038517342,"user_tz":-540,"elapsed":43312,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"72599e39-b78b-461c-ea31-d3dd5f481129"},"source":["network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 13s 7ms/step - loss: 0.2656 - accuracy: 0.9233\n","Epoch 2/5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1065 - accuracy: 0.9680\n","Epoch 3/5\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0711 - accuracy: 0.9787\n","Epoch 4/5\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0511 - accuracy: 0.9851\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9887\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1c7853e820>"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"d2-JZZPLavHd"},"source":["훈련하는 동안 두 개의 정보가 출력됩니다. 훈련 데이터에 대한 네트워크의 손실과 정확도입니다.\n","\n","훈련 데이터에 대해 0.989(98.9%)의 정확도를 금방 달성합니다. 이제 테스트 세트에서도 모델이 잘 작동하는지 확인해 보겠습니다:"]},{"cell_type":"code","metadata":{"id":"YFCyuCAvavHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038518799,"user_tz":-540,"elapsed":1468,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"f0614786-ceb6-44b2-c160-7abdac86972f"},"source":["test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9795\n"]}]},{"cell_type":"code","metadata":{"id":"a_wrMEkVavHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038518799,"user_tz":-540,"elapsed":7,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"9c093565-7abe-44dc-ba0d-8e48b9467cfe"},"source":["print('test_acc:', test_acc)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["test_acc: 0.9794999957084656\n"]}]},{"cell_type":"markdown","metadata":{"id":"DEIgwx2savHd"},"source":["테스트 세트의 정확도는 97.8%로 나왔습니다. 훈련 세트 정확도보다는 약간 낮습니다. 훈련 정확도와 테스트 정확도 사이의 차이는 과대적합 때문입니다. 이는 머신 러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경향을 말합니다. 과대적합은 3장에서 자세하게 논의하겠습니다.\n","\n","이것으로 첫 번째 예제가 마무리되었습니다. 20줄 미만의 파이썬 코드로 손글씨 숫자를 분류하는 신경망을 만들고 훈련시켰습니다. 다음 장에서 여기서 보았던 코드 하나하나를 상세하게 설명하고 이들이 의미하는 바를 명확하게 설명하겠습니다. 이제 텐서, 신경망에 주입하는 데이터의 저장 형태, 층을 만들어주는 텐서 연산, 신경망을 훈련 샘플로부터 학습시키는 경사 하강법에 대해 알아보겠습니다."]},{"cell_type":"markdown","metadata":{"id":"r66ahJoBpuZB"},"source":["## TODO 1: 은닉층의 유닛수\n","1. 첫 번째 은닉층의 유닛수를 64로 바꾸면 테스트 데이터 정확도는?\n","2. 첫 번째 은닉층의 유닛수를 1024로 바꾸면 테스트 데이터 정확도는?"]},{"cell_type":"code","metadata":{"id":"4IDFygWMp_P3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038531072,"user_tz":-540,"elapsed":12275,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"5abaef74-bf74-467f-e8f5-746f70b47bed"},"source":["# TODO: 64일 때 테스트 정확도 출력\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(64, activation='relu', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3955 - accuracy: 0.8944\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.2004 - accuracy: 0.9430\n","Epoch 3/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.1537 - accuracy: 0.9554\n","Epoch 4/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.1256 - accuracy: 0.9638\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.9692\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.9664\n","test_acc: 0.9664000272750854\n"]}]},{"cell_type":"code","source":["# TODO: 1024일 때 테스트 정확도 출력\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(1024, activation='relu', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"id":"6TXiPlir0ZEv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038541312,"user_tz":-540,"elapsed":10243,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"8f88b0a9-0954-4ef3-94ee-155ed957dd39"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2419 - accuracy: 0.9290\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9721\n","Epoch 3/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0586 - accuracy: 0.9818\n","Epoch 4/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0413 - accuracy: 0.9870\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9906\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9810\n","test_acc: 0.9810000061988831\n"]}]},{"cell_type":"markdown","metadata":{"id":"vUh9JOIWvENW"},"source":["## TODO 2: 은닉층의 활성화 함수\n","1. 첫 번째 은닉층의 활성화 함수를 sigmoid로 바꾸면 테스트 데이터 정확도는?\n","2. 첫 번째 은닉층의 활성화 함수를 tanh로 바꾸면 테스트 데이터 정확도는?"]},{"cell_type":"code","metadata":{"id":"FUQvr-vGvNb2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038553714,"user_tz":-540,"elapsed":12406,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"967a6783-dddd-471f-d34e-bf6d7fee4cfa"},"source":["# TODO: sigmoid일 때 테스트 정확도 출력\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='sigmoid', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4594 - accuracy: 0.8771\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.9219\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.2144 - accuracy: 0.9370\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9495\n","Epoch 5/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.1465 - accuracy: 0.9571\n","313/313 [==============================] - 1s 3ms/step - loss: 0.1467 - accuracy: 0.9566\n","test_acc: 0.95660001039505\n"]}]},{"cell_type":"code","source":["# TODO: tanh일 때 테스트 정확도 출력\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='tanh', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"id":"RWtdtR701RPK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038565220,"user_tz":-540,"elapsed":11515,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"ef92f327-fb2f-4a0f-ba34-63d32e450bad"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3393 - accuracy: 0.9010\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1830 - accuracy: 0.9465\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1243 - accuracy: 0.9637\n","Epoch 4/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0921 - accuracy: 0.9725\n","Epoch 5/5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0714 - accuracy: 0.9789\n","313/313 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9752\n","test_acc: 0.9751999974250793\n"]}]},{"cell_type":"markdown","metadata":{"id":"bFBGsy7rvmef"},"source":["## TODO 3: Softmax\n","1. [-1, 0, 1]에서 softmax 결과 0이 선택될 확률은?\n","2. [1, 2, 3]에서 softmax 결과 3이 선택될 확률은?\n","3. [10, 20, 30]에서 softmax 결과 30이 선택될 확률은?"]},{"cell_type":"code","metadata":{"id":"mU7fWLF9voWN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038565221,"user_tz":-540,"elapsed":22,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"1fbb041e-cc60-407c-ad5d-c894e829b07e"},"source":["# TODO: 위의 질문에 대한 답을 출력하세요.\n","# Softmax 함수는 모든 범위의 실수 값들을 받아들여 확률로 변환 가능한 장점이 있습니다.\n","\n","from scipy.special import softmax\n","\n","# 1번\n","print(softmax([-1, 0, 1])[1])\n","\n","# 2번\n","print(softmax([1, 2, 3])[2])\n","\n","# 3번\n","print(softmax([10, 20, 30])[2])"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0.24472847105479764\n","0.6652409557748218\n","0.999954600070331\n"]}]},{"cell_type":"markdown","metadata":{"id":"WWfVyZ6zwWl6"},"source":["## TODO 4: Optimizer\n","https://keras.io/api/optimizers/sgd/\n","1. optimizer에 SGD()를 썼을 때 테스트 정확도는?\n","2. optimizer에 SGD(learning_rate=0.1, momentum=0.9, nesterov=True)를 썼을 때 테스트 정확도는?\n","3. optimizer에 Adam()을 썼을 때 테스트 정확도는?"]},{"cell_type":"code","metadata":{"id":"lRIYd7X54t0F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038577753,"user_tz":-540,"elapsed":12551,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"a929bb56-ce82-4b2c-f5ef-3f10e3add590"},"source":["# TODO: SGD()를 사용했을 때의 테스트 정확도 출력\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer=optimizers.SGD(),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 1.1152 - accuracy: 0.7556\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5210 - accuracy: 0.8733\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4190 - accuracy: 0.8899\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3730 - accuracy: 0.8995\n","Epoch 5/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3447 - accuracy: 0.9057\n","313/313 [==============================] - 1s 2ms/step - loss: 0.3176 - accuracy: 0.9150\n","test_acc: 0.9150000214576721\n"]}]},{"cell_type":"code","source":["# TODO: SGD(learning_rate=0.1, momentum=0.9, nesterov=True)를 사용했을 때의 테스트 정확도 출력\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer=optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"id":"at3KajAe14FI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038589714,"user_tz":-540,"elapsed":11969,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"f397d9e5-6253-4529-87a5-085367e43629"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 3s 4ms/step - loss: 0.2278 - accuracy: 0.9334\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9733\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.9815\n","Epoch 4/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0421 - accuracy: 0.9870\n","Epoch 5/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9914\n","313/313 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9805\n","test_acc: 0.9804999828338623\n"]}]},{"cell_type":"code","source":["# TODO: Adam()을 사용했을 때의 테스트 정확도 출력\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer=optimizers.Adam(),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"id":"L23hC8nm68S3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038600720,"user_tz":-540,"elapsed":11025,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"d5300060-a817-4431-a89a-1cc5017df75a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2670 - accuracy: 0.9246\n","Epoch 2/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.1087 - accuracy: 0.9684\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0711 - accuracy: 0.9791\n","Epoch 4/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.9857\n","Epoch 5/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0369 - accuracy: 0.9891\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0662 - accuracy: 0.9790\n","test_acc: 0.9789999723434448\n"]}]},{"cell_type":"markdown","metadata":{"id":"TV9Fp7jmAnVC"},"source":["## TODO 5: 정규화의 영향\n","\n","1. 이미지들을 정규화하지 않고 학습시켰을 때 테스트 정확도는?"]},{"cell_type":"code","metadata":{"id":"1-jMqhf1AdRm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038612778,"user_tz":-540,"elapsed":12072,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"363a2c27-ad9a-4cb7-f819-e0824de7c2df"},"source":["# TODO: [0, 1]로의 정규화 없이 이미지를 일차원 배열로 reshape만 수행했을 때의 테스트 정확도 출력\n","conv_train_images = train_images.reshape((60000, 28 * 28))\n","conv_test_images = test_images.reshape((10000, 28 * 28))\n","\n","from tensorflow.keras import optimizers\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n","network.add(layers.Dense(10, activation='softmax'))\n","\n","network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.fit(conv_train_images, cat_train_labels, epochs=5, batch_size=128)\n","test_loss, test_acc = network.evaluate(conv_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 4.8265 - accuracy: 0.9027\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.7055 - accuracy: 0.9535\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4516 - accuracy: 0.9647\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3804 - accuracy: 0.9715\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.2938 - accuracy: 0.9766\n","313/313 [==============================] - 1s 3ms/step - loss: 0.7714 - accuracy: 0.9624\n","test_acc: 0.9624000191688538\n"]}]},{"cell_type":"markdown","source":["## TODO 6: 최적화\n","\n","1. 자유롭게 MLP (Multi-layer Perceptron)를 만들어서 Test 정확도를 98.2% 이상으로 만들어보세요. (층 추가 가능)"],"metadata":{"id":"HV7c9PPv5c3b"}},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","from tensorflow.keras import initializers\n","\n","norm_train_images = train_images.reshape((60000, 28 * 28))      # 6만개의 일차원 배열로 재해석 (각 배열은 길이 784=28*28)\n","norm_train_images = norm_train_images.astype('float32') / 255   # [0, 255]의 정수를 [0, 1]의 실수로 변환\n","norm_test_images = test_images.reshape((10000, 28 * 28))\n","norm_test_images = norm_test_images.astype('float32') / 255\n","\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(256, activation='relu', input_shape=(512,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(10, activation='softmax', kernel_initializer=\"glorot_uniform\"))\n","\n","network.compile(optimizer=optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","# Early Stopping\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=20, batch_size=256, callbacks=[callback])\n","network.summary()\n","\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"id":"Q7MTFakW38xC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679038818371,"user_tz":-540,"elapsed":20983,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"11a8d864-ed0e-4217-ab0d-93539dbca94c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.2610 - accuracy: 0.9209\n","Epoch 2/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9740\n","Epoch 3/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9830\n","Epoch 4/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0379 - accuracy: 0.9886\n","Epoch 5/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9921\n","Epoch 6/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9945\n","Epoch 7/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.9966\n","Epoch 8/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9981\n","Epoch 9/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9993\n","Epoch 10/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9997\n","Epoch 11/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9998\n","Epoch 12/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9998\n","Epoch 13/20\n","235/235 [==============================] - 1s 3ms/step - loss: 9.7740e-04 - accuracy: 0.9999\n","Epoch 14/20\n","235/235 [==============================] - 1s 4ms/step - loss: 6.2815e-04 - accuracy: 1.0000\n","Epoch 15/20\n","235/235 [==============================] - 1s 4ms/step - loss: 5.1987e-04 - accuracy: 1.0000\n","Epoch 16/20\n","235/235 [==============================] - 1s 3ms/step - loss: 4.5772e-04 - accuracy: 1.0000\n","Epoch 17/20\n","235/235 [==============================] - 1s 4ms/step - loss: 4.1306e-04 - accuracy: 1.0000\n","Epoch 18/20\n","235/235 [==============================] - 1s 5ms/step - loss: 3.7191e-04 - accuracy: 1.0000\n","Epoch 19/20\n","235/235 [==============================] - 1s 4ms/step - loss: 3.4964e-04 - accuracy: 1.0000\n","Epoch 20/20\n","235/235 [==============================] - 1s 3ms/step - loss: 3.1866e-04 - accuracy: 1.0000\n","Model: \"sequential_16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_39 (Dense)            (None, 512)               401920    \n","                                                                 \n"," dense_40 (Dense)            (None, 256)               131328    \n","                                                                 \n"," dense_41 (Dense)            (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 535,818\n","Trainable params: 535,818\n","Non-trainable params: 0\n","_________________________________________________________________\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9839\n","test_acc: 0.9839000105857849\n"]}]},{"cell_type":"markdown","metadata":{"id":"SRzvurdzBZf1"},"source":["##TODO 7: 마무리\n","\n","오늘 실습에서 인공신경망의 성능에 영향을 준 요인들을 나열해보세요."]},{"cell_type":"code","source":["# A: 은닉층의 유닛수, 은닉층의 활성화 함수, Softmax, Optimizer, 정규화의 영황, Weight Initization, batch_size, epochs"],"metadata":{"id":"Nw1JBoMT8Vdm","executionInfo":{"status":"ok","timestamp":1679038625399,"user_tz":-540,"elapsed":5,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","from tensorflow.keras import initializers\n","import tensorflow as tf\n","\n","norm_train_images = train_images.reshape((60000, 28 * 28))      # 6만개의 일차원 배열로 재해석 (각 배열은 길이 784=28*28)\n","norm_train_images = norm_train_images.astype('float32') / 255   # [0, 255]의 정수를 [0, 1]의 실수로 변환\n","norm_test_images = test_images.reshape((10000, 28 * 28))\n","norm_test_images = norm_test_images.astype('float32') / 255\n","\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(256, activation='relu', input_shape=(512,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(10, activation='softmax', kernel_initializer=\"glorot_uniform\"))\n","\n","network.compile(optimizer=optimizers.Adam(),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","# Early Stopping\n","callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","# Learning Rate Scheduler\n","def scheduler(epoch, lr):\n","  if epoch < 5: return lr\n","  else: return lr * tf.math.exp(-0.1)\n","\n","callback2 = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=20, batch_size=256, callbacks=[callback1, callback2])\n","network.summary()\n","\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ai62SO6NXXYZ","executionInfo":{"status":"ok","timestamp":1679039545136,"user_tz":-540,"elapsed":23750,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"b3636f42-abc6-4954-bf61-91ecf750a9b5"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","235/235 [==============================] - 2s 4ms/step - loss: 0.2678 - accuracy: 0.9225 - lr: 0.0010\n","Epoch 2/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9714 - lr: 0.0010\n","Epoch 3/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0584 - accuracy: 0.9817 - lr: 0.0010\n","Epoch 4/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0405 - accuracy: 0.9875 - lr: 0.0010\n","Epoch 5/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9915 - lr: 0.0010\n","Epoch 6/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9950 - lr: 9.0484e-04\n","Epoch 7/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9974 - lr: 8.1873e-04\n","Epoch 8/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9985 - lr: 7.4082e-04\n","Epoch 9/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9994 - lr: 6.7032e-04\n","Epoch 10/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9998 - lr: 6.0653e-04\n","Epoch 11/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9999 - lr: 5.4881e-04\n","Epoch 12/20\n","235/235 [==============================] - 1s 3ms/step - loss: 9.1918e-04 - accuracy: 1.0000 - lr: 4.9659e-04\n","Epoch 13/20\n","235/235 [==============================] - 1s 4ms/step - loss: 6.5429e-04 - accuracy: 1.0000 - lr: 4.4933e-04\n","Epoch 14/20\n","235/235 [==============================] - 1s 4ms/step - loss: 5.7532e-04 - accuracy: 1.0000 - lr: 4.0657e-04\n","Epoch 15/20\n","235/235 [==============================] - 1s 4ms/step - loss: 4.8419e-04 - accuracy: 1.0000 - lr: 3.6788e-04\n","Epoch 16/20\n","235/235 [==============================] - 1s 4ms/step - loss: 4.2072e-04 - accuracy: 1.0000 - lr: 3.3287e-04\n","Epoch 17/20\n","235/235 [==============================] - 1s 4ms/step - loss: 3.7222e-04 - accuracy: 1.0000 - lr: 3.0119e-04\n","Epoch 18/20\n","235/235 [==============================] - 1s 3ms/step - loss: 3.4266e-04 - accuracy: 1.0000 - lr: 2.7253e-04\n","Epoch 19/20\n","235/235 [==============================] - 1s 3ms/step - loss: 3.0697e-04 - accuracy: 1.0000 - lr: 2.4660e-04\n","Epoch 20/20\n","235/235 [==============================] - 1s 4ms/step - loss: 2.8313e-04 - accuracy: 1.0000 - lr: 2.2313e-04\n","Model: \"sequential_30\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_86 (Dense)            (None, 512)               401920    \n","                                                                 \n"," dense_87 (Dense)            (None, 256)               131328    \n","                                                                 \n"," dense_88 (Dense)            (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 535,818\n","Trainable params: 535,818\n","Non-trainable params: 0\n","_________________________________________________________________\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9837\n","test_acc: 0.9836999773979187\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","from tensorflow.keras import initializers\n","import tensorflow as tf\n","\n","norm_train_images = train_images.reshape((60000, 28 * 28))      # 6만개의 일차원 배열로 재해석 (각 배열은 길이 784=28*28)\n","norm_train_images = norm_train_images.astype('float32') / 255   # [0, 255]의 정수를 [0, 1]의 실수로 변환\n","norm_test_images = test_images.reshape((10000, 28 * 28))\n","norm_test_images = norm_test_images.astype('float32') / 255\n","\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(256, activation='relu', input_shape=(512,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(10, activation='softmax', kernel_initializer=\"glorot_uniform\"))\n","\n","network.compile(optimizer=optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","# Early Stopping\n","callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","# Learning Rate Scheduler\n","def scheduler(epoch, lr):\n","  if epoch < 5: return lr\n","  else: return lr * tf.math.exp(-0.1)\n","\n","callback2 = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=20, batch_size=256, callbacks=[callback1, callback2])\n","network.summary()\n","\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6jYPYcw0bAH8","executionInfo":{"status":"ok","timestamp":1679039589460,"user_tz":-540,"elapsed":23447,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"899363e5-71d3-43cb-bfc9-88a3349b3f2d"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","235/235 [==============================] - 2s 5ms/step - loss: 0.2546 - accuracy: 0.9237 - lr: 0.1000\n","Epoch 2/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0872 - accuracy: 0.9740 - lr: 0.1000\n","Epoch 3/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0559 - accuracy: 0.9826 - lr: 0.1000\n","Epoch 4/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.9890 - lr: 0.1000\n","Epoch 5/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9930 - lr: 0.1000\n","Epoch 6/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9959 - lr: 0.0905\n","Epoch 7/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.9978 - lr: 0.0819\n","Epoch 8/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9990 - lr: 0.0741\n","Epoch 9/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9997 - lr: 0.0670\n","Epoch 10/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9998 - lr: 0.0607\n","Epoch 11/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9999 - lr: 0.0549\n","Epoch 12/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 0.0497\n","Epoch 13/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - lr: 0.0449\n","Epoch 14/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 0.0407\n","Epoch 15/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - lr: 0.0368\n","Epoch 16/20\n","235/235 [==============================] - 1s 5ms/step - loss: 9.8503e-04 - accuracy: 1.0000 - lr: 0.0333\n","Epoch 17/20\n","235/235 [==============================] - 1s 4ms/step - loss: 9.2795e-04 - accuracy: 1.0000 - lr: 0.0301\n","Epoch 18/20\n","235/235 [==============================] - 1s 3ms/step - loss: 8.7625e-04 - accuracy: 1.0000 - lr: 0.0273\n","Epoch 19/20\n","235/235 [==============================] - 1s 4ms/step - loss: 8.4614e-04 - accuracy: 1.0000 - lr: 0.0247\n","Epoch 20/20\n","235/235 [==============================] - 1s 3ms/step - loss: 8.1022e-04 - accuracy: 1.0000 - lr: 0.0223\n","Model: \"sequential_31\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_89 (Dense)            (None, 512)               401920    \n","                                                                 \n"," dense_90 (Dense)            (None, 256)               131328    \n","                                                                 \n"," dense_91 (Dense)            (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 535,818\n","Trainable params: 535,818\n","Non-trainable params: 0\n","_________________________________________________________________\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9835\n","test_acc: 0.9835000038146973\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","from tensorflow.keras import initializers\n","import tensorflow as tf\n","\n","norm_train_images = train_images.reshape((60000, 28 * 28))      # 6만개의 일차원 배열로 재해석 (각 배열은 길이 784=28*28)\n","norm_train_images = norm_train_images.astype('float32') / 255   # [0, 255]의 정수를 [0, 1]의 실수로 변환\n","norm_test_images = test_images.reshape((10000, 28 * 28))\n","norm_test_images = norm_test_images.astype('float32') / 255\n","\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(256, activation='relu', input_shape=(512,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(256, activation='relu', input_shape=(256,), kernel_initializer=initializers.HeNormal()))\n","# network.add(layers.Dense(512, activation='selu', input_shape=(28 * 28,), kernel_initializer='lecun_normal'))\n","# network.add(layers.Dense(256, activation='selu', input_shape=(512,), kernel_initializer='lecun_normal'))\n","network.add(layers.Dense(10, activation='softmax', kernel_initializer=\"glorot_uniform\"))\n","\n","network.compile(optimizer=optimizers.Nadam(),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","# Early Stopping\n","callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","# Learning Rate Scheduler\n","def scheduler(epoch, lr):\n","  if epoch < 5: return lr\n","  else: return lr * tf.math.exp(-0.1)\n","\n","callback2 = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=20, batch_size=256, callbacks=[callback1, callback2])\n","network.summary()\n","\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"id":"IRbjcuPEcfSL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679039449680,"user_tz":-540,"elapsed":27088,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"4439d6bd-5123-403b-ad8c-7535d6eff3ef"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","235/235 [==============================] - 3s 5ms/step - loss: 0.2508 - accuracy: 0.9283 - lr: 0.0010\n","Epoch 2/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0831 - accuracy: 0.9751 - lr: 0.0010\n","Epoch 3/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9835 - lr: 0.0010\n","Epoch 4/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9885 - lr: 0.0010\n","Epoch 5/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9918 - lr: 0.0010\n","Epoch 6/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9942 - lr: 9.0484e-04\n","Epoch 7/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9965 - lr: 8.1873e-04\n","Epoch 8/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - lr: 7.4082e-04\n","Epoch 9/20\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9991 - lr: 6.7032e-04\n","Epoch 10/20\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - lr: 6.0653e-04\n","Epoch 11/20\n","235/235 [==============================] - 1s 5ms/step - loss: 5.5083e-04 - accuracy: 1.0000 - lr: 5.4881e-04\n","Epoch 12/20\n","235/235 [==============================] - 1s 4ms/step - loss: 2.6596e-04 - accuracy: 1.0000 - lr: 4.9659e-04\n","Epoch 13/20\n","235/235 [==============================] - 1s 4ms/step - loss: 1.5330e-04 - accuracy: 1.0000 - lr: 4.4933e-04\n","Epoch 14/20\n","235/235 [==============================] - 1s 5ms/step - loss: 1.2421e-04 - accuracy: 1.0000 - lr: 4.0657e-04\n","Epoch 15/20\n","235/235 [==============================] - 1s 5ms/step - loss: 1.0590e-04 - accuracy: 1.0000 - lr: 3.6788e-04\n","Epoch 16/20\n","235/235 [==============================] - 1s 5ms/step - loss: 9.2373e-05 - accuracy: 1.0000 - lr: 3.3287e-04\n","Epoch 17/20\n","235/235 [==============================] - 1s 4ms/step - loss: 8.2797e-05 - accuracy: 1.0000 - lr: 3.0119e-04\n","Epoch 18/20\n","235/235 [==============================] - 1s 5ms/step - loss: 7.5102e-05 - accuracy: 1.0000 - lr: 2.7253e-04\n","Epoch 19/20\n","235/235 [==============================] - 1s 4ms/step - loss: 6.8348e-05 - accuracy: 1.0000 - lr: 2.4660e-04\n","Epoch 20/20\n","235/235 [==============================] - 1s 5ms/step - loss: 6.2307e-05 - accuracy: 1.0000 - lr: 2.2313e-04\n","Model: \"sequential_27\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_76 (Dense)            (None, 512)               401920    \n","                                                                 \n"," dense_77 (Dense)            (None, 256)               131328    \n","                                                                 \n"," dense_78 (Dense)            (None, 256)               65792     \n","                                                                 \n"," dense_79 (Dense)            (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 601,610\n","Trainable params: 601,610\n","Non-trainable params: 0\n","_________________________________________________________________\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0733 - accuracy: 0.9847\n","test_acc: 0.9847000241279602\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","from tensorflow.keras import initializers\n","import tensorflow as tf\n","\n","norm_train_images = train_images.reshape((60000, 28 * 28))      # 6만개의 일차원 배열로 재해석 (각 배열은 길이 784=28*28)\n","norm_train_images = norm_train_images.astype('float32') / 255   # [0, 255]의 정수를 [0, 1]의 실수로 변환\n","norm_test_images = test_images.reshape((10000, 28 * 28))\n","norm_test_images = norm_test_images.astype('float32') / 255\n","\n","network = models.Sequential()\n","network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(256, activation='relu', input_shape=(512,), kernel_initializer=initializers.HeNormal()))\n","network.add(layers.Dense(10, activation='softmax', kernel_initializer=\"glorot_uniform\"))\n","\n","network.compile(optimizer=optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","# Early Stopping\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","\n","network.fit(norm_train_images, cat_train_labels, epochs=20, batch_size=256, callbacks=[callback])\n","network.summary()\n","\n","test_loss, test_acc = network.evaluate(norm_test_images, cat_test_labels)\n","print('test_acc:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWU9y9JWg6Cg","executionInfo":{"status":"ok","timestamp":1679039396302,"user_tz":-540,"elapsed":26140,"user":{"displayName":"민동준","userId":"06420174620131971170"}},"outputId":"23e7e35d-d536-4d09-8d70-b5b94728e039"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","235/235 [==============================] - 1s 3ms/step - loss: 0.2536 - accuracy: 0.9232\n","Epoch 2/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9739\n","Epoch 3/20\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0554 - accuracy: 0.9830\n","Epoch 4/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9882\n","Epoch 5/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9920\n","Epoch 6/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0186 - accuracy: 0.9947\n","Epoch 7/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9964\n","Epoch 8/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9977\n","Epoch 9/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9990\n","Epoch 10/20\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9995\n","Epoch 11/20\n","235/235 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 0.9999\n","Epoch 12/20\n","235/235 [==============================] - 1s 4ms/step - loss: 9.8668e-04 - accuracy: 1.0000\n","Epoch 13/20\n","235/235 [==============================] - 1s 5ms/step - loss: 7.5412e-04 - accuracy: 1.0000\n","Epoch 14/20\n","235/235 [==============================] - 1s 5ms/step - loss: 6.3202e-04 - accuracy: 1.0000\n","Epoch 15/20\n","235/235 [==============================] - 1s 4ms/step - loss: 6.0532e-04 - accuracy: 1.0000\n","Epoch 16/20\n","235/235 [==============================] - 1s 6ms/step - loss: 4.9469e-04 - accuracy: 1.0000\n","Epoch 17/20\n","235/235 [==============================] - 2s 6ms/step - loss: 4.3581e-04 - accuracy: 1.0000\n","Epoch 18/20\n","235/235 [==============================] - 1s 3ms/step - loss: 4.0871e-04 - accuracy: 1.0000\n","Epoch 19/20\n","235/235 [==============================] - 2s 7ms/step - loss: 3.7327e-04 - accuracy: 1.0000\n","Epoch 20/20\n","235/235 [==============================] - 1s 5ms/step - loss: 3.4198e-04 - accuracy: 1.0000\n","Model: \"sequential_26\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_73 (Dense)            (None, 512)               401920    \n","                                                                 \n"," dense_74 (Dense)            (None, 256)               131328    \n","                                                                 \n"," dense_75 (Dense)            (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 535,818\n","Trainable params: 535,818\n","Non-trainable params: 0\n","_________________________________________________________________\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0630 - accuracy: 0.9854\n","test_acc: 0.9854000210762024\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cmPkMJ1bi453","executionInfo":{"status":"ok","timestamp":1679040137405,"user_tz":-540,"elapsed":2,"user":{"displayName":"민동준","userId":"06420174620131971170"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bbKw4ukSj44J"},"execution_count":null,"outputs":[]}]}